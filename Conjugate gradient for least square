#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Apr 12 21:48:14 2021

"""

import numpy as np
import time

#Minimize Ax = b (overdetermined) using conjugate gradient
#Checks first for invalid size
def LSqCG(A,b,K):
    (m,n) = A.shape
    d = len(b)
    if m < n or m != d:
        return -1
    
    Q = (A.T)@A
    c = (A.T)@b
    return cGrad(Q,c,K)
    

#Solve Ax=b using conjugate gradient
#K is specified n. iteration for conjgrad
#Time complexity O(n^2K)
def cGrad(A,b,K):
    n = len(A)
    x = np.random.rand(n)
    r = A@x-b
    d = r
    
    #Each iteration is O(n^2)
    for i in range(K):
        QD = A@d
        INV = np.dot(d,QD)
        
        alpha = np.dot(r,d)/INV
        x = x-alpha*d
        
        r = A@x - b
        
        beta = np.dot(r,QD)/INV
        d = r - beta*d

    return x

#Examples
A = np.array([[1,2,3,4],
              [1,3,2,4],
              [1,5,1,2],
              [1,2,2,1],
              [2,1,1,3]], float)

b = np.array([1,2,3,4,5],float)

x = LSqCG(A,b,4)
print(x)

np.random.seed(10)
RANDM = np.random.rand(10000,1000)*10
RANDV = np.random.rand(10000)*1000

y = LSqCG(RANDM,RANDV,100)
print(y[::100]) #display entries to illustrate convergence
        
        
    
